#user  nobody;
#启动进程,通常设置成和cpu的数量相等
worker_processes  1;

#全局错误日志及PID文件
#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid;

#工作模式及连接数上限
events {

	#单个后台worker process进程的最大并发链接数
    worker_connections  1024;

	#epoll是多路复用IO(I/O Multiplexing)中的一种方式,
    #仅用于linux2.6以上内核,可以大大提高nginx的性能
    #use   epoll;

	 # 并发总数是 worker_processes 和 worker_connections 的乘积
    # 即 max_clients = worker_processes * worker_connections
    # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4  为什么
    # 为什么上面反向代理要除以4，应该说是一个经验值
    # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000
    # worker_connections 值的设置跟物理内存大小有关
    # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数
    # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右
    # 我们来看看360M内存的VPS可以打开的文件句柄数是多少：
    # $ cat /proc/sys/fs/file-max
    # 输出 34336
    # 32000 < 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内
    # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置
    # 使得并发总数小于操作系统可以打开的最大文件数目
    # 其实质也就是根据主机的物理CPU和内存进行配置
    # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。
    # ulimit -SHn 65535

}

http {
    #设定mime类型,类型由mime.type文件定义
    include       mime.types;

	default_type  application/octet-stream;

	#设定日志格式
    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，
    #对于普通应用，必须设为 on,
    #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，
    #以平衡磁盘与网络I/O处理速度，降低系统的uptime.
    sendfile        on;
    #tcp_nopush     on;

	#连接超时时间
    #keepalive_timeout  0;
    keepalive_timeout  65;

    #开启gzip压缩
    #gzip  on;

	#设定请求缓冲
    #client_header_buffer_size    128k;
    #large_client_header_buffers  4 128k;

	#upstream local_tomcat {
	#	server localhost:8080;
	#}

	#设置由 fail_timeout 定义的时间段内连接该主机的失败次数，以此来断定 fail_timeout 定义的时间段内该主机是否可用。默认情况下这个数值设置为 1。零值的话禁用这个数量的尝试。
    #设置在指定时间内连接到主机的失败次数，超过该次数该主机被认为不可用。
    #这里是在30s内尝试2次失败即认为主机不可用！
	upstream backend {
			ip_hash;
            #server   localhost:8080;
			server   localhost:8083;
			server   localhost:8084;

 		    # 下面介绍几种负载均衡策略，其中轮询、weight、ip_hash是nginx内置的，可以直接使用。fair和url_hash需要第三方支持才可以使用。
			# 1、轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
			#server localhost:8288;
			#server localhost:8289;
			#server localhost:8290;

			# 2、weight：指定权重，按照权重进行请求的分配。wight和访问比例成正比，适合后端服务器性能不均的情况。
			# 下面的配置就会经常访问8288的服务。如果后端服务器8288 down掉，能够立刻切换到8299或者8290。如果8288再次启动，则又能回到原有的权重配置上。8288可以继续提供服务。
			# server localhost:8288 weight=10;
			# server localhost:8289 weight=1;
			# server localhost:8290 weight=1;

			# 3、ip_hash：每个请求按照ip的hash结果进行分配，这样的话每个访客固定请求一个后端服务器，可以解决session没共享的问题。
			# 如果8288 down掉，则依然可以访问，可能会缓存8289或者8290。如果8288启动，则会从8289或8290切换到8288。
			# ip_hash;
			# server localhost:8288;
			# server localhost:8289;
			# server localhost:8290;

			# 4、fair（第三方）：后端服务器响应时间短的优先分配。
			# fair;
			# server localhost:8288;
			# server localhost:8289;
			# server localhost:8290;

			# 5、url_hash（第三方）：按访问的url的hash结果来分配请求，这样相同url会分配到相同的后端服务器。适合后端服务器有缓存的情况。
			# hash $request_uri;
			# hash_method crc32;
			# server localhost:8288;
			# server localhost:8289;
			# server localhost:8290;

    }

	#设定虚拟主机配置
    server {
	    #侦听8081端口
        listen       8081;

		#监听地址
        server_name  localhost:8081;

        #charset koi8-r;

		#定义服务器的默认网站根目录位置
        #root html;

        #设定本虚拟主机的访问日志
        #access_log  logs/host.access.log  main;

        #location /demo/ {
		location / {
			proxy_connect_timeout 30;
			proxy_send_timeout 60;
			proxy_read_timeout 60;
            #root   html;
			# proxy_pass http://localhost:8080;
			proxy_pass http://backend;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }

        # proxy the PHP scripts to Apache listening on 127.0.0.1:80
        #
        #location ~ \.php$ {
        #    proxy_pass   http://127.0.0.1;
        #}

        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
        #
        #location ~ \.php$ {
        #    root           html;
        #    fastcgi_pass   127.0.0.1:9000;
        #    fastcgi_index  index.php;
        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
        #    include        fastcgi_params;
        #}

        # deny access to .htaccess files, if Apache's document root
        # concurs with nginx's one
        #
        #location ~ /\.ht {
        #    deny  all;
        #}
    }


    # another virtual host using mix of IP-, name-, and port-based configuration
    #
    #server {
    #    listen       8000;
    #    listen       somename:8080;
    #    server_name  somename  alias  another.alias;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}


    # HTTPS server
    #
    #server {
    #    listen       443 ssl;
    #    server_name  localhost;

    #    ssl_certificate      cert.pem;
    #    ssl_certificate_key  cert.key;

    #    ssl_session_cache    shared:SSL:1m;
    #    ssl_session_timeout  5m;

    #    ssl_ciphers  HIGH:!aNULL:!MD5;
    #    ssl_prefer_server_ciphers  on;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}

}
